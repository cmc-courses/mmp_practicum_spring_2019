{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RNNs & attention.\n",
    "\n",
    "## \tComputer Practicum for 317 group, spring 2019\n",
    "\n",
    "Start: 14.04.19\n",
    "\n",
    "Deadline (soft): 25.04.19 06:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should implement a sequence to sequence model (https://arxiv.org/abs/1409.3215),\n",
    "using RNNs (e. g. LSTM by Schmidhuber et al.) and attention models (https://arxiv.org/abs/1409.0473).\n",
    "\n",
    "You are not allowed to copy and paste uncredited code from any sources.\n",
    "If you do, you must CITE the source and provide EVERY line of the copied code with a comment expalining what the corresponding line does. You will be punished for borrowings (even for the cited ones) with some deduction from your final score (which is left to the ultimate discretion of the teaching assistant).  Of course, we will not trigger on every minor similarity case, but we will understand that non-trivial parts of the task were copied from elsewhere.\n",
    "\n",
    "In this assignment we will also encourage good code and punish bad code.\n",
    "We also ask you to provide useful about APIs and usability of the prototypes.\n",
    "You will get some extra points for good code.\n",
    "\n",
    "``The data is taken from this competition https://datasouls.com/c/cft-contest/description#\n",
    "You could refer the solution of the winners: https://spark-in.me/post/cft-spelling-2018, ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tqdm\n",
    "import copy\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The datasets and dataloaders (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you will work with sequences of tokens.\n",
    "We have to map the tokens into indices to feed it into the model.\n",
    "Let's create a hierarchy of classes to work with sequences for our convenience.\n",
    "\n",
    "This class handles only one array of sequences, but it performs all the forward and backward transformations (like encoding and decoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset containing one np array of strings.\n",
    "    Handles encoding of strings to word index arrays,\n",
    "    backward decoding.\n",
    "    \"\"\"\n",
    "    # It is strongly recommended to work with batches,\n",
    "    # not with single sequebces.\n",
    "    # As the sequences are of different length and batches are 'rectangular',\n",
    "    # we introduce a special token for padding\n",
    "    PAD = \"ø\"\n",
    "    # In this task we will work only with the known tokens extracted from the dataset\n",
    "    # But we shouldn't crash randomly if we encounter an unknown token.\n",
    "    # We introduce a token to replace any unknown token\n",
    "    UNK = \"?\"\n",
    "    # We will feed the decoder with a start-of-sequence token as the first input\n",
    "    SOS = \"^\"\n",
    "    # The end-of-sequence token. We append it to the end of every sequence \n",
    "    # so that the RNN would know that the sequence is finished.\n",
    "    # Followed by the end of the tensor or PAD tokens.=\n",
    "    EOS = \"$\"\n",
    "    def __init__(self, X, token_list):\n",
    "        \"\"\"\n",
    "        X: np.ndarray of strings\n",
    "        token_list: list of tokens\n",
    "        token_list must be disjoint with special_tokens\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        assert isinstance(token_list, list)\n",
    "        \n",
    "        self.X = X\n",
    "        self.token_list = token_list\n",
    "        self.special_tokens = [self.PAD, self.UNK, self.SOS, self.EOS]\n",
    "        \n",
    "        assert not (set(self.special_tokens) & set(self.token_list))\n",
    "        \n",
    "        self.tokens =  self.special_tokens + token_list\n",
    "        self.encoder = {\n",
    "            token: token_id\n",
    "            for token_id, token in enumerate(self.tokens)\n",
    "        }\n",
    "        \n",
    "        # We will need it later\n",
    "        self.pad_id = self.encoder[self.PAD]\n",
    "        self.unk_id = self.encoder[self.UNK]\n",
    "        self.sos_id = self.encoder[self.SOS]\n",
    "        self.eos_id = self.encoder[self.EOS]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def encode(self, sequence):\n",
    "        \"\"\"\n",
    "        sequence: a sequence (a string)\n",
    "        result: list of token indices with eos index in the end, \n",
    "        len(result) == len(sequence) + 1\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        \n",
    "        #### TODO\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def decode(self, sequence, keep_pad=False):\n",
    "        \"\"\"\n",
    "        sequence: array of word indices\n",
    "        keep_pad: boolean flag whether decoding should stop when eos token is seen\n",
    "        \n",
    "        returns: \n",
    "            if keep_pad returns a list of all tokens (including EOS and PAD)\n",
    "            if not keep_pad returns a string of tokens, dropping EOS and PAD\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for idx in sequence:\n",
    "            token = self.tokens[idx]\n",
    "            if token == self.EOS and not keep_pad:\n",
    "                break\n",
    "            result.append(token)\n",
    "        \n",
    "        if keep_pad:\n",
    "            return result\n",
    "        return \" \".join(result)\n",
    "    \n",
    "    def encode_batch(self, sequences):\n",
    "        return [self.encode(sequence) for sequence in sequences]\n",
    "    \n",
    "    def decode_batch(self, sequences, keep_pad=False):\n",
    "        return [self.decode(sequence, keep_pad) for sequence in sequences]    \n",
    "    \n",
    "    def prepare_item(self, item):\n",
    "        \"\"\"\n",
    "        item: an item from dataset\n",
    "        result: dict with \n",
    "            'raw':string without word index encoding\n",
    "            'item': word index encoded string\n",
    "            'len':len of the raw string\n",
    "            'mask':has 1 on positions where item[postions] != pad_id\n",
    "            (for one line it is [1]*len(item))\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        result[\"raw\"] = item\n",
    "        result[\"item\"] = torch.from_numpy(np.array(self.encode(item)))\n",
    "        result[\"len\"] = len(item)\n",
    "        result[\"mask\"] = (result[\"item\"] != self.pad_id).float()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def extract_item(self, cur_x):   \n",
    "        \"\"\"\n",
    "        You might use this function to perform some\n",
    "        transformations if you don't want to store the\n",
    "        transformation results\n",
    "        \"\"\"\n",
    "        return cur_x\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        result = {}\n",
    "        \n",
    "        cur_x = self.extract_item(self.X[idx])\n",
    "        \n",
    "        result[\"x\"] = self.prepare_item(cur_x)\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the class. Notice that it should work not only with single letters, but with arbitrary tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [['мама', 'мыла', 'раму'], ['папа', 'чинил', 'раму']]\n",
    "token_list = ['мама', 'папа', 'раму']\n",
    "\n",
    "dataset = SeqDataset(X, token_list)\n",
    "elem_0, elem_1 = dataset[0], dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test EOS token \n",
    "assert elem_0['x']['item'][-1] == dataset.eos_id\n",
    "assert elem_1['x']['item'][-1] == dataset.eos_id\n",
    "\n",
    "# test tokens and result matching\n",
    "assert dataset.tokens[elem_0['x']['item'][0]] == X[0][0]\n",
    "assert dataset.tokens[elem_1['x']['item'][0]] == X[1][0]\n",
    "\n",
    "# test UNK token\n",
    "assert elem_0['x']['item'][1] == dataset.unk_id\n",
    "assert elem_1['x']['item'][1] == dataset.unk_id\n",
    "assert dataset.decode(elem_0['x']['item']) == 'мама ? раму'\n",
    "assert dataset.decode(elem_1['x']['item']) == 'папа ? раму'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are going to work in the sequence to sequence setting, we will use two sequences (input and the correct output).\n",
    "The following class inherits the previous class (simply adding Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(SeqDataset):\n",
    "    \"\"\"\n",
    "    Same as the previous,\n",
    "    but it handles two columns: input sequence and output sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, X, Y, token_list):\n",
    "        super().__init__(X, token_list)\n",
    "        assert len(X) == len(Y)        \n",
    "        self.Y = Y\n",
    "        \n",
    "    def extract_item(self, cur_x, cur_y):            \n",
    "        return cur_x, cur_y\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        result = {}\n",
    "        \n",
    "        cur_x, cur_y = self.extract_item(self.X[idx], self.Y[idx])\n",
    "        \n",
    "        result[\"x\"] = self.prepare_item(cur_x)\n",
    "        result[\"y\"] = self.prepare_item(cur_y)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function splits the data into train, test and validaton datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(X, Y, token_list, train_val_test=[0.8,0.1,0.1]): \n",
    "    \"\"\"\n",
    "    X, Y: np.ndarrays of equal length, X -- input sequence, Y -- output sequence\n",
    "    token_list -- list of tokens from BOTH X and Y\n",
    "    train_val_test: ratio to split the dataset\n",
    "    \"\"\"\n",
    "    assert isinstance(X, np.ndarray) and isinstance(Y, np.ndarray)\n",
    "    assert sum(train_val_test) == 1.0\n",
    "    assert len(X) == len(Y)\n",
    "                      \n",
    "    train_size = int(len(X) * train_val_test[0])\n",
    "    val_size = int(len(X) * train_val_test[1])\n",
    "    test_size = len(X) - train_size - val_size\n",
    "    \n",
    "    indices = np.arange(len(X))\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "    \n",
    "    train = Seq2SeqDataset(X[train_indices], Y[train_indices], token_list)\n",
    "    val = Seq2SeqDataset(X[val_indices], Y[val_indices], token_list)\n",
    "    test = Seq2SeqDataset(X[test_indices], Y[test_indices], token_list)\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first you could work with a toy problem: sequence reversal. Dataset is generated randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(df):\n",
    "    \"\"\"\n",
    "    df: dataframe from the CTF competition\n",
    "    returns: a list of all tokens in the data frame\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    \n",
    "    for original, corrected in zip(df[\"fullname\"], df[\"fullname_true\"]):\n",
    "        counter.update(original)\n",
    "        if not pd.isna(corrected):\n",
    "            counter.update(corrected)\n",
    "            \n",
    "    return list(counter.keys())\n",
    "\n",
    "def random_word(length, alphabet):\n",
    "    \"\"\"\n",
    "    length: int, the exact length of sequence to generate\n",
    "    alphabet: a list of tokens to generate from\n",
    "    returns: a string of random tokens of desired length\n",
    "    \"\"\"\n",
    "    token_indexes = np.random.randint(0, len(alphabet), length)\n",
    "    token = \"\".join([alphabet[x] for x in token_indexes])\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `generate_random_reverse_dataset` generates the dataset of random sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_reverse_dataset(n_samples, max_len, token_list, unique_x = True, train_val_test=[0.8,0.1,0.1]):    \n",
    "    \"\"\"\n",
    "    n_samples: size of the dataset\n",
    "    max_len: maximum length of the sequences to genretate\n",
    "    unique_x: every x must be unique in the dataset\n",
    "    train_val_test: list of ratios to split the dataset\n",
    "    \n",
    "    returns: 3 Seq2Seq datasets\n",
    "    \"\"\"\n",
    "    new_X = []\n",
    "    new_Y = []\n",
    "    \n",
    "    seen_x = set()\n",
    "    while len(new_X) < n_samples:  \n",
    "        x = random_word(max_len, token_list)\n",
    "        y = \"\".join(reversed(x))\n",
    "        \n",
    "        if x in seen_x:\n",
    "            continue\n",
    "        \n",
    "        if unique_x:\n",
    "            seen_x.add(x)\n",
    "        new_X.append(x)\n",
    "        new_Y.append(y)\n",
    "    \n",
    "    \n",
    "    X = np.array(new_X)[:n_samples]\n",
    "    Y = np.array(new_Y)[:n_samples]\n",
    "    \n",
    "    train, val, test = prepare_dataset(X, Y, token_list, train_val_test)    \n",
    "    \n",
    "    return train, val, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collate_sequences function is used by the DataLoader to merge separate results of `Seq2SeqDataset.__getitem__` into tensors of required shape, to prepare the masks et c.\n",
    "\n",
    "**Hint:** use pad_sequence from pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_sequences(sample_list):\n",
    "    \"\"\"\n",
    "    sample_list: list of samples, \n",
    "    each was provided by dataset.__getitem__(idx)\n",
    "    \"\"\"\n",
    "    \n",
    "    ######### TODO\n",
    "    \n",
    "    result = dict(x=x, y=y, mask_x=mask_x, mask_y=mask_y, raw_x=raw_x, raw_y=raw_y, len_x=len_x, len_y=len_y)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = generate_random_reverse_dataset(\n",
    "    n_samples=100000,\n",
    "    max_len=20,\n",
    "    token_list=list('йцукенгшщзхъфывапролджэячсмитьбю')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test you code once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batcher = DataLoader(train, collate_fn=collate_sequences, batch_size=64, shuffle=True)\n",
    "val_batcher = DataLoader(val, collate_fn=collate_sequences, batch_size=64, shuffle=False)\n",
    "test_batcher = DataLoader(test, collate_fn=collate_sequences, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_batch_structure(batch, train_batcher):\n",
    "    assert isinstance(batch['raw_y'][0], str)\n",
    "    assert isinstance(batch['raw_x'][0], str)\n",
    "\n",
    "    assert isinstance(batch['x'], torch.Tensor)\n",
    "    assert batch['x'].dtype == torch.int64\n",
    "\n",
    "    assert isinstance(batch['y'], torch.Tensor)\n",
    "    assert batch['y'].dtype == torch.int64\n",
    "\n",
    "    assert torch.all(batch['x'][np.arange(len(batch['x'])), batch['len_x']] == train.eos_id)\n",
    "    assert torch.all(batch['y'][np.arange(len(batch['y'])), batch['len_y']] == train.eos_id)\n",
    "    \n",
    "    for row, row_len, row_mask in zip(batch['x'], batch['len_x'], batch['mask_x']):\n",
    "        for position, (char_id, mask_value) in enumerate(zip(row, row_mask)):\n",
    "            if position < row_len:\n",
    "                assert char_id not in train_batcher.dataset.encode(train_batcher.dataset.special_tokens)\n",
    "                assert mask_value == 1.0\n",
    "            elif position == row_len:\n",
    "                assert char_id == train_batcher.dataset.eos_id\n",
    "                assert mask_value == 1.0\n",
    "            else:\n",
    "                assert char_id == train_batcher.dataset.pad_id\n",
    "                assert mask_value == 0.0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an ugly way to take the first batch\n",
    "for batch in train_batcher:\n",
    "    break\n",
    "    \n",
    "check_batch_structure(batch, train_batcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, do not remove the outputs of your experimental models from the notebook.\n",
    "If the training is not interrupted extremely early, keep the plots.\n",
    "In the end of the notebook describe everything you tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq losses (1 point)\n",
    "\n",
    "In the next cell we define the losses we will track in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(log_probs, y, mask_y, pad_value):\n",
    "    \"\"\"\n",
    "    log_probs: logs of probability\n",
    "    Please, keep your usage of softmax, \n",
    "    logsoftmax, crossentropy etc consistent\n",
    "    \n",
    "    It is advised to ignore pad_values in y.\n",
    "    Refer documentation of (e.g) nll_loss.\n",
    "    \"\"\"\n",
    "    ##### TODO\n",
    "\n",
    "    assert result.shape == torch.Size()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_accuracy(pred, true):\n",
    "    \"\"\"\n",
    "    The target metric for all the tasks.\n",
    "    Fraction of exact matches of the strings\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(pred) == len(true)\n",
    "    corrects = 0\n",
    "    for cur_pred, cur_true in zip(pred, true):\n",
    "        corrects += cur_pred == cur_true\n",
    "        \n",
    "    return corrects/len(pred)\n",
    "\n",
    "def character_accuracy(pred, true):\n",
    "    \"\"\"\n",
    "    Returns: fraction of correct characters in the batch\n",
    "    and\n",
    "    mean fraction of correct characters for every prediction-answer pair\n",
    "    \"\"\"\n",
    "    assert len(pred) == len(true)\n",
    "\n",
    "    total_characters = 0\n",
    "    values = []\n",
    "    lengths = []\n",
    "    for cur_pred, cur_true in zip(pred, true):\n",
    "        values.append(sum([c1 == c2 for c1, c2 in zip(cur_pred, cur_true)]))\n",
    "        cur_len = max(len(cur_true), len(cur_pred))\n",
    "        lengths.append(cur_len)\n",
    "            \n",
    "    \n",
    "    values = np.array(values)\n",
    "    lengths = np.array(lengths)\n",
    "\n",
    "    return (values/lengths).mean(), values.sum()/lengths.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is created to hide the batch structure and how to use the model.\n",
    "It is supposed to be convenient.\n",
    "If used properly, it can facilitate even major changes of the API of the model class.\n",
    "\n",
    "The idea is that if you significantly change some functions of the model, you'll only have to change their calls in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqUser:\n",
    "    \"\"\"\n",
    "    A helper class that knows structure of the batch and losses.\n",
    "    Should facilitate API changes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        # we keep track \n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.samples = []\n",
    "        self.raw_samples = []\n",
    "        self.attention_weights = []\n",
    "\n",
    "    def train_forward(self, model, batch, params):\n",
    "        \"\"\"\n",
    "        Forward function during training can be very distinct from the \n",
    "        forward function during usage,\n",
    "        as we can use teacher forcing (and we have the correct answer)\n",
    "        \"\"\"\n",
    "        result = model.train_forward(\n",
    "            batch['x'], batch['mask_x'], batch['len_x'], \n",
    "            batch['y'], batch['mask_y'], batch['len_y'], \n",
    "            teacher_forcing_prob=params['teacher_forcing_prob']\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    def forward(self, model, batch, params):\n",
    "        \"\"\"\n",
    "        The 'fair' forward (which has no access to the ground truth)\n",
    "        \"\"\"\n",
    "        result = model.forward(\n",
    "            batch['x'], batch['mask_x'], batch['len_x'], \n",
    "            max_output_length=batch['y'].shape[1]\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def compute_loss(self, forward_result, batch, params):\n",
    "        \"\"\"\n",
    "        forward_result: the output of train_forward\n",
    "        batch: the batch that generated the forward_result\n",
    "        \n",
    "        returns: scalar tensor, loss on the batch\n",
    "        \n",
    "        The function that knows what loss function we have and how\n",
    "        to call it with forward_result and the batch\n",
    "        \"\"\"\n",
    "        \n",
    "        log_probs, preds, debug_info = forward_result\n",
    "        result = seq2seq_loss(\n",
    "            log_probs, batch['y'], batch['mask_y'],\n",
    "            pad_value=self.dataset.pad_id\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    def compute_target_metric(self, forward_result, batch, params):\n",
    "        \"\"\"\n",
    "        forward_result: the output of train_forward\n",
    "        batch: the batch that generated the forward_result\n",
    "        \n",
    "        returns: float, the target metric on the batch\n",
    "        \n",
    "        Computes the metric we aim to improve, but we\n",
    "        cannot optimize it (for instance, the number of perfect matches)\n",
    "        \"\"\"\n",
    "        \n",
    "        log_probs, preds, debug_info = forward_result\n",
    "        text_preds = self.dataset.decode_batch(preds)\n",
    "        \n",
    "        target_metric = seq2seq_accuracy(text_preds, batch['raw_y'])\n",
    "        \n",
    "        return target_metric\n",
    "    \n",
    "    def compute_eval_metrics(self, forward_result, batch, batch_id, tag, params):\n",
    "        \"\"\"\n",
    "        forward_result: the output of train_forward\n",
    "        batch: the batch that generated the forward_result\n",
    "        batch_id: number of the batch in the dataset\n",
    "        tag: dataset tag\n",
    "        \n",
    "        \n",
    "        returns: dict of string => float\n",
    "        \n",
    "        Function that computes all other metrics we might wish, \n",
    "        but we don't optimize them or aim to improve\n",
    "        \"\"\"\n",
    "        log_probs, preds, debug_info = forward_result\n",
    "        text_preds = self.dataset.decode_batch(preds)\n",
    "        \n",
    "        # Use this code to track the evolution of predictions\n",
    "        # Not the best way, actually.\n",
    "        \"\"\"\n",
    "        if batch_id == 0 and tag == \"val\":\n",
    "            n_samples = params.get(\"print_eval_max\", 0)\n",
    "            answers = list(zip(batch['raw_x'], text_preds, batch['raw_y']))[:n_samples]\n",
    "            self.samples.append(answers)\n",
    "            self.raw_samples.append(\n",
    "                list(zip(\n",
    "                    self.dataset.decode_batch(batch['x'], keep_pad=True), \n",
    "                    self.dataset.decode_batch(preds, keep_pad=True),\n",
    "                    self.dataset.decode_batch(batch['y'], keep_pad=True)\n",
    "                ))[:n_samples]\n",
    "            )\n",
    "            self.attention_weights.append(debug_info['attention_weights'][:n_samples])\n",
    "            for answer in answers:\n",
    "                print(\"{} || {} || {}\".format(*answer))\n",
    "\n",
    "        \"\"\"\n",
    "        char_acc = character_accuracy(text_preds, batch['raw_y'])\n",
    "        \n",
    "        result = dict(zip([\"char_acc_micro\", \"char_acc_macro\"], char_acc))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def use(self, model, sequence, max_output_length=100):\n",
    "        \"\"\"\n",
    "        model: sequence to sequence model\n",
    "        sequence: list of tokens\n",
    "        returns: decoded string, matrix of predictions and debug_info \n",
    "        (attention matrix, original and predicted sequences with padding)\n",
    "        \"\"\"\n",
    "        \n",
    "        item = self.dataset.prepare_item(sequence)\n",
    "        \n",
    "        x = item['item']\n",
    "        with torch.no_grad():\n",
    "            log_probs, preds, debug_info = model.forward(\n",
    "                x.reshape(1, -1), \n",
    "                item['mask'].reshape(1, -1), \n",
    "                np.array([item['len']]),\n",
    "                max_output_length=max_output_length\n",
    "            )\n",
    "        decoded = self.dataset.decode_batch(preds)\n",
    "        \n",
    "        debug_info['decoded_padded'] = self.dataset.decode(preds[0], keep_pad=True)\n",
    "        debug_info['sequence_padded'] = self.dataset.decode(x, keep_pad=True)\n",
    "        \n",
    "        return decoded, preds.detach().numpy(), debug_info\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model (4 points)\n",
    "\n",
    "There're plenty asserts in the class and below!\n",
    "\n",
    "* **2 points** for a basic rnn (LSTM or GRU seq2seq without attention)\n",
    "* **2 points** for rnn attention\n",
    "\n",
    "\n",
    "__KEEP ALL THE CODE FOR ALL MODELS THAT YOU TRY (AND WHICH ARE TRAINABLE)__\n",
    "\n",
    "#### Model description\n",
    "\n",
    "Complete the following model.\n",
    "You can change the APIs, but please comment that.\n",
    "You can change the parameters of the constructor freely (but keep sos_id and eos_id)\n",
    "Try implementing several different models.\n",
    "For instance, a simple unidirectional seq2seq without attention.\n",
    "Try building a general model where you can switch between various modes (GRU, LSTM, number of directions, number of layers, dropout, kinds of attention) by passing parameters.\n",
    "\n",
    "If you train on GPU, try training on CPU and check, if the impact of the GPU is as big as you expect. Describe what you see.\n",
    "\n",
    "If you use GPU, try inserting *.to(device), *.cuda() as little as possible.\n",
    "\n",
    "Try boosting the encoder by using built-in torch.LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, embedding_size,\n",
    "                 hidden_size, num_layers, vocabulary_size,\n",
    "                 sos_id, eos_id,\n",
    "                 use_attention=True,\n",
    "                 **params):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.eos_id = eos_id\n",
    "        self.sos_id = sos_id\n",
    "        \n",
    "        self.use_attention = use_attention\n",
    "        \n",
    "        self.params = params\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.num_directions = 2\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.effective_hidden_size = num_layers * self.hidden_size * self.num_directions\n",
    "        self.encoder_output_size = self.num_directions * hidden_size\n",
    "        self.decoder_output_size = self.num_directions * hidden_size\n",
    "        self.context_size = self.encoder_output_size\n",
    "        self.decoder_input_size = embedding_size + self.num_directions * hidden_size        \n",
    "        \n",
    "        ##### TODO\n",
    "        \n",
    "    def encode(self, X, mask_x, len_x):\n",
    "        batch_size, max_length = X.shape\n",
    "        embedded = self.embeddings(X)     \n",
    "        \n",
    "        debug_info = defaultdict(list)\n",
    "        \n",
    "        #### TODO        \n",
    "\n",
    "        for pos in range(max_length):\n",
    "            # YOU MUST NOT iterate through the samples in the batch!\n",
    "            #### TODO            \n",
    "        \n",
    "        #### TODO\n",
    "        \n",
    "        # some tests\n",
    "        required_shape = (batch_size, max_length, self.effective_hidden_size)\n",
    "        assert hidden.shape == required_shape, (hidden.shape, required_shape)\n",
    "        \n",
    "        required_shape = (batch_size, max_length, self.encoder_output_size)\n",
    "        assert outputs.shape == required_shape, (outputs.shape, required_shape)\n",
    "        \n",
    "        if self.params['encoder_use_last_valid_state']:\n",
    "            result_state = hidden[torch.arange(batch_size), len_x]\n",
    "        else:\n",
    "            result_state = hidden[:, -1]\n",
    "        \n",
    "        return result_state, outputs, debug_info\n",
    "    \n",
    "    \n",
    "    def attention(self, key, encoder_output, mask_x, len_x):\n",
    "        debug_info = {}\n",
    "        batch_size, max_length = key.shape\n",
    "        input_length = encoder_output.shape[1]\n",
    "        \n",
    "        required_shape = (batch_size, 2 * self.hidden_size)\n",
    "        assert key.shape == required_shape, (key.shape, required_shape)\n",
    "        \n",
    "        attention_logits = #### TODO \n",
    "        \n",
    "        required_shape = (batch_size, input_length)\n",
    "        assert attention_logits.shape == required_shape, (attention_logits.shape, required_shape)\n",
    "        \n",
    "        #### TODO\n",
    "        \n",
    "        attention_weights = #### TODO\n",
    "        context = #### TODO\n",
    "                \n",
    "        required_shape = (batch_size, self.context_size)\n",
    "        assert context.shape == required_shape, (context.shape, required_shape)\n",
    "        \n",
    "        ####TMP\n",
    "        return context, attention_weights.squeeze(-1)\n",
    "    \n",
    "    def decode(self, encoder_state, encoder_output, mask_x, len_x, max_output_length=None, real_output=None, teacher_forcing=False):   \n",
    "        assert max_output_length is not None or real_output is not None\n",
    "        \n",
    "        if real_output is not None:\n",
    "            assert max_output_length is None\n",
    "            max_output_length = real_output.shape[1]\n",
    "        else:\n",
    "            assert real_output is None\n",
    "            \n",
    "        if teacher_forcing:\n",
    "            assert real_output is not None\n",
    "        \n",
    "        batch_size, _ = encoder_state.shape\n",
    "        debug_info = defaultdict(list)\n",
    "        \n",
    "        ##### TODO        \n",
    "        \n",
    "        last_output_ids = torch.from_numpy(np.array([self.sos_id for i in range(batch_size)]))\n",
    "        \n",
    "        #### TODO\n",
    "        \n",
    "        for step_id in range(max_output_length):\n",
    "            if step_id > 0 and teacher_forcing:\n",
    "                last_output_ids = real_output[:, step_id - 1]\n",
    "            last_output = self.embeddings(last_output_ids)\n",
    "            \n",
    "            #### TODO\n",
    "            \n",
    "            if use_attention:\n",
    "                context, attention_weight  = self.attention(output, encoder_output, mask_x, len_x)\n",
    "                #### TODO\n",
    "            \n",
    "            #### TODO        \n",
    "        \n",
    "        if use_attention:\n",
    "            debug_info['attention_weights'] = torch.cat(attention_weights, dim=1).detach().numpy()\n",
    "        \n",
    "        return probs, preds, debug_info\n",
    "    \n",
    "    \n",
    "    def forward(self, x, mask_x, len_x, max_output_length): \n",
    "        #### TODO\n",
    "\n",
    "        return decoded\n",
    "        \n",
    "    \n",
    "    def train_forward(self, x, mask_x, len_x, y, mask_y, len_y, teacher_forcing_prob=0.0):\n",
    "        teacher_forcing = False\n",
    "        if np.random.rand() < teacher_forcing_prob:\n",
    "            teacher_forcing = True\n",
    "        \n",
    "        if not teacher_forcing:\n",
    "            max_output_length = y.shape[1]\n",
    "            y = None\n",
    "        else:\n",
    "            max_output_length = None\n",
    "        \n",
    "        #### TODO\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model here for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model = AttentionModel(\n",
    "    64, 128, 3, len(train.encoder),\n",
    "    train.sos_id, train.eos_id,\n",
    "    use_attention=False,\n",
    "    params={'encoder_use_last_valid_state':True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a loss object on the train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = Seq2SeqUser(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of reasonable parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"epochs\":30,\n",
    "    \"teacher_forcing_prob\":0.5,\n",
    "    \"log_params\":{\n",
    "        \"figsize\":(20, 10),\n",
    "        \"show_every\":5\n",
    "    },\n",
    "    \"validate_every\":50,\n",
    "    \"validation_max_batches\":10,\n",
    "    \"print_eval_max\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tests as always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # an ugly way to take the first batch\n",
    "for batch in train_batcher:\n",
    "    break\n",
    "    \n",
    "forward_result = loss_object.train_forward(seq2seq_model, batch, params)\n",
    "\n",
    "assert forward_result[1].dtype == torch.int64\n",
    "assert isinstance(forward_result[2], defaultdict)\n",
    "\n",
    "loss = loss_object.compute_loss(forward_result, batch, params)\n",
    "assert loss.requires_grad == True\n",
    "\n",
    "# A randomly initialize model is expected to have losses (on this token set) like this\n",
    "assert 4.0 <= loss and loss <= 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_output_length = 59\n",
    "decoded, predictions, debug_info = loss_object.use(\n",
    "    seq2seq_model, list(\"пушкиналександрсергеевич\"), max_output_length=max_output_length\n",
    ")\n",
    "\n",
    "assert isinstance(decoded, list)\n",
    "assert isinstance(decoded[0], str)\n",
    "\n",
    "assert isinstance(predictions, np.ndarray)\n",
    "assert predictions.shape == (1, max_output_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class is to facilitate the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, backward_callback=None, iteration_callback=None):\n",
    "        \"\"\"\n",
    "        model: a seq2seq model\n",
    "        optimizer: an optimizer to optimize the model\n",
    "        Use the callbacks for lr scheduling and gradient clipping\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.iteration_callback = iteration_callback\n",
    "        self.backward_callback = backward_callback\n",
    "        \n",
    "        self.metrics = defaultdict(list)\n",
    "        self.metric_steps = defaultdict(list)\n",
    "        self.total_epochs = 0\n",
    "        self.total_iterations = 0\n",
    "    \n",
    "    \n",
    "    def log(self, value, tag, step):\n",
    "        \"\"\"\n",
    "        value: tensor or float\n",
    "        tag: string, name of the logged value\n",
    "        step: iteration of the process\n",
    "        \"\"\"\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            value = value.detach().numpy()\n",
    "        \n",
    "        self.metrics[tag].append(value)\n",
    "        self.metric_steps[tag].append(step)\n",
    " \n",
    "    def show_logs(self, params):\n",
    "        \"\"\"\n",
    "        shows the logs every show_every iterations\n",
    "        \"\"\"\n",
    "        if self.total_iterations % params['show_every'] != 0:\n",
    "            return\n",
    "        \n",
    "        display.clear_output()\n",
    "        \n",
    "        tags = sorted(self.metrics.keys())\n",
    "        figures = [tag.split('/')[0] for tag in tags]\n",
    "        previous_figure = None\n",
    "        \n",
    "        \n",
    "        for tag, figure  in zip(tags, figures):\n",
    "            if previous_figure != figure:\n",
    "                plt.show()\n",
    "                plt.figure(figsize=params['figsize'])\n",
    "                plt.title(figure)\n",
    "            plt.plot(self.metric_steps[tag], self.metrics[tag], label=tag)\n",
    "            previous_figure = figure\n",
    "            plt.legend()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def evaluate(self, batcher, loss_object, tag, params):\n",
    "        \"\"\"\n",
    "        batcher: DatasetLodader\n",
    "        loss_object: Seq2SeqUser\n",
    "        tag: dataset tag (train, val)\n",
    "        params: dict, evaluation params\n",
    "        \"\"\"\n",
    "        if self.total_iterations % params['validate_every'] != 0:\n",
    "            return\n",
    "        \n",
    "        max_batches = min(params['validation_max_batches'], len(batcher))\n",
    "        self.model.eval()\n",
    "        \n",
    "        loss_accum = 0\n",
    "        size_accum = 0\n",
    "        target_metric_accum = 0\n",
    "        eval_metric_dict = defaultdict(list)\n",
    "        for batch_id, batch in enumerate(tqdm.tqdm_notebook(batcher, desc=\"evaluation\", total=max_batches)):\n",
    "            if batch_id > max_batches:\n",
    "                break\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                forward_result = loss_object.forward(self.model, batch, params)\n",
    "                loss = loss_object.compute_loss(forward_result, batch, params)\n",
    "                loss = loss.detach().numpy()\n",
    "            \n",
    "            target_metric = loss_object.compute_target_metric(forward_result, batch, params)\n",
    "            eval_metrics = loss_object.compute_eval_metrics(forward_result, batch, batch_id, tag, params)\n",
    "            for key, value in eval_metrics.items():\n",
    "                eval_metric_dict[key].append(value)\n",
    "            \n",
    "            target_metric_accum += target_metric * len(batch['x'])\n",
    "            loss_accum += loss * len(batch['x'])\n",
    "            size_accum += len(batch['x'])\n",
    "        \n",
    "        self.log(value=loss_accum/size_accum, tag=\"loss/eval/\" + tag, step=self.total_iterations)\n",
    "        self.log(value=target_metric_accum/size_accum, tag=\"target_metric/eval\" + tag, step=self.total_iterations)\n",
    "        \n",
    "        for key, values in eval_metrics.items():\n",
    "            self.log(value=np.mean(values), tag = key + \"/eval/\" + tag, step=self.total_iterations)\n",
    "        \n",
    "        torch.save(self.model.state_dict(), \"./model_state.tc\")\n",
    "        torch.save((self.metrics, self.total_iterations, self.optimizer), \"./trainer.tc\")\n",
    "        self.model.train()\n",
    "    \n",
    "    def train(self, train_batcher, loss_object, val_batcher, params={}):\n",
    "        \"\"\"\n",
    "        train_batcher: DataLoader with seq2seq dataset\n",
    "        loss_object: Seq2SeqUser\n",
    "        val_batcher: DataLoader with seq2seq dataset\n",
    "        params: dict, contains the parameters of training\n",
    "        \n",
    "        Runs the training process, logging the loss and displaying it\n",
    "        \"\"\"\n",
    "        \n",
    "        for epoch_id in range(params['epochs']):\n",
    "            for iteration_id, batch in enumerate(tqdm.tqdm_notebook(train_batcher)):\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                iteration_start_time = time.time()\n",
    "                forward_result = loss_object.train_forward(self.model, batch, params)\n",
    "                loss = loss_object.compute_loss(forward_result, batch, params)\n",
    "                \n",
    "\n",
    "                    \n",
    "                loss.backward()\n",
    "                if self.backward_callback is not None:\n",
    "                    self.backward_callback()\n",
    "                    \n",
    "                self.optimizer.step()\n",
    "                if self.iteration_callback is not None:\n",
    "                    self.iteration_callback()\n",
    "                \n",
    "                self.log(loss, tag=\"loss/batch_train\", step=self.total_iterations)\n",
    "                self.log(time.time(), tag=\"time_elapsed\", step=self.total_iterations)\n",
    "                self.log(time.time() - iteration_start_time, tag=\"time/train\", step=self.total_iterations)\n",
    "                self.evaluate(train_batcher, loss_object, \"train\", params)\n",
    "                self.evaluate(val_batcher, loss_object, \"val\", params)\n",
    "                \n",
    "\n",
    "                self.show_logs(params['log_params'])\n",
    "                \n",
    "                self.total_iterations += 1\n",
    "            \n",
    "            self.total_epochs += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with simple seq2seq (2 points)\n",
    "\n",
    "Experiments go here. Achieve some quality!\n",
    "\n",
    "You will get the complete score only if you provide some experiments with architectures. A simple bidirectional model is able to learn reverse sequence (0.7 — 0.8 accuracy) in 2 -- 4 hours.\n",
    "\n",
    "Don't forget to provide some plots or tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to optimize the parameters of the CURRENT MODEL\n",
    "# Try different optimizers\n",
    "optimizer = torch.optim.Adam(seq2seq_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(seq2seq_model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the callbacks for gradient clipping (it can be important for RNNs) and learning rate scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train(train_batcher=train_batcher, val_batcher=val_batcher, loss_object=loss_object, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, batcher, loss_object, max_batches, tag, params):\n",
    "    \"\"\"\n",
    "    model: seq2seq model\n",
    "    batcher: Dataloader, test dataset\n",
    "    loss_object: Seq2SeqUser\n",
    "    max_batcher: number of the first batches to evaluate\n",
    "    tag: dataset name\n",
    "    params: evaluation params\n",
    "    \n",
    "    performs the evaluation on the test dataset\n",
    "\n",
    "    \"\"\"\n",
    "    max_batches=min(max_batches, len(batcher))\n",
    "    model.eval()\n",
    "\n",
    "    loss_accum = 0\n",
    "    size_accum = 0\n",
    "    target_metric_accum = 0\n",
    "    eval_metric_dict = defaultdict(list)\n",
    "    for batch_id, batch in enumerate(tqdm.tqdm_notebook(batcher, desc=\"evaluation\", total=max_batches)):  \n",
    "        if batch_id > max_batches:\n",
    "            break\n",
    "        with torch.no_grad():\n",
    "            forward_result = loss_object.forward(model, batch, params)\n",
    "            loss = loss_object.compute_loss(forward_result, batch, params)\n",
    "            loss = loss.detach().numpy()\n",
    "\n",
    "        target_metric = loss_object.compute_target_metric(forward_result, batch, params)\n",
    "        eval_metrics = loss_object.compute_eval_metrics(forward_result, batch, batch_id, tag, params)\n",
    "        for key, value in eval_metrics.items():\n",
    "            eval_metric_dict[key].append(value)\n",
    "\n",
    "        target_metric_accum += target_metric * len(batch['x'])\n",
    "        loss_accum += loss * len(batch['x'])\n",
    "        size_accum += len(batch['x'])\n",
    "\n",
    "\n",
    "    result = {}\n",
    "    result['loss'] = loss_accum/size_accum\n",
    "    result['target'] = target_metric_accum/size_accum\n",
    "    for key, values in eval_metrics.items():\n",
    "        result[key] = np.mean(values) \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_result_test = evaluate_test(\n",
    "    seq2seq_model, test_batcher, loss_object, max_batches=100000, tag=\"test\", params=params\n",
    ")\n",
    "\n",
    "evaluate_result_train = evaluate_test(\n",
    "    seq2seq_model, train_batcher, loss_object, max_batches=100, tag=\"train\", params=params\n",
    ")\n",
    "\n",
    "evaluate_result_val = evaluate_test(\n",
    "    seq2seq_model, val_batcher, loss_object, max_batches=100, tag=\"val\", params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with attention seq2seq  (2 points)\n",
    "\n",
    "Compare performance (and times for training) of seq2seq model and attention seq2seq model.\n",
    "A bidirectional model with attention and should be able to learn reverse (== copy) sequence in around 20-30 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention visualization  \n",
    "\n",
    "Now let's look at what the attention mechanism has learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement this function\n",
    "# Tip: use seaborn heatmap\n",
    "def visualize_attention(text_x, text_y, attention_weights):\n",
    "    ### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use(line, model, loss_object, max_output_length):\n",
    "    \"\"\"\n",
    "    line: line to transform\n",
    "    model: seq2seq model\n",
    "    loss_object: Seq2SeqUser for the model\n",
    "    \n",
    "    uses and prints\n",
    "    \"\"\"\n",
    "    decoded, preds, debug_info = loss_object.use(seq2seq_model, list(line),\n",
    "                                                 max_output_length=max_output_length)\n",
    "    decoded = decoded[0]\n",
    "    attention_weights = debug_info['attention_weights'][0]\n",
    "    print(line, \" -> \", decoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_and_visualize(line, model, loss_object, max_output_length):\n",
    "    \"\"\"\n",
    "    line: line to transform\n",
    "    model: seq2seq model\n",
    "    loss_object: Seq2SeqUser for the model\n",
    "    \n",
    "    uses the model, prints the output and visualizes the attention mask\n",
    "    \"\"\"\n",
    "    decoded, preds, debug_info = loss_object.use(seq2seq_model, list(line),\n",
    "                                                 max_output_length=max_output_length)\n",
    "    attention_weights = debug_info['attention_weights'][0]\n",
    "    print(line, \" -> \", decoded[0])\n",
    "    visualize_attention(\n",
    "        text_x=debug_info['sequence_padded'],\n",
    "        text_y=debug_info['decoded_padded'],\n",
    "        attention_weights=attention_weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this if your loss object stores the samples from the evaluation\n",
    "# for item in zip(loss_object.raw_samples[0], loss_object.attention_weights[0]):\n",
    "#     visualize_attention(item[0][0], item[0][2], item[1])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize attention weights and explain them.\n",
    "Try to generate various inputs to produce interesting outputs.\n",
    "Try to break the model and make in return nonsense for a reasonable input.\n",
    "\n",
    "Describe what you see.\n",
    "Why is attention like that? (Results may differ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, try to change the length of the input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "Tell us: what did you learn, what did you like, what puzzled you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: spelling correction data (3 points)\n",
    "\n",
    "If you feel strength you can train a model on the competition data.\n",
    "It is possible to train a model that achieves at least 0.5 of exact match accuracy on CPU with 8 GB of memory in 12 hours with moderate batches of at least 64, while watching videos and having >400 open tabs in browser (Firefox, actually).\n",
    "\n",
    "If you beat this threshold (0.5 of exact match accuracy), you will be awarded the points for this part.\n",
    "If your score is super high (to be determined after the deadline), you will be awarded by some points.\n",
    "\n",
    "Also you can use the complete dataset (with retained correct entries) to improve models perfomance.\n",
    "\n",
    "Maybe you need to play with teacher forcing params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_surnames_dataset(csv_path, drop_correct, unique_x = True, train_val_test=[0.8,0.1,0.1]):\n",
    "    \"\"\"\n",
    "    Loads the competition dataset.\n",
    "    drop_correct: boolean flag whether to include the entries\n",
    "    where X[i] == Y[i] (no misspelling)\n",
    "    unique_x: every x in the dataset must be unique\n",
    "    \n",
    "    returns: 4 Seq2Seq datasets: train, val, test\n",
    "    and correct: the dataset of surnames with no mistakes\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    token_list = get_tokens(data)\n",
    "    \n",
    "    X = data['fullname']\n",
    "    Y = data['fullname_true']\n",
    "    \n",
    "    mask = Y.isna()\n",
    "\n",
    "    Y.loc[mask] = X[mask]\n",
    "    \n",
    "    \n",
    "    new_X = []\n",
    "    new_Y = []\n",
    "    correct = []\n",
    "    \n",
    "    seen_x = set()\n",
    "    for x, y in zip(X.values, Y.values):   \n",
    "        if x in seen_x:\n",
    "            continue\n",
    "            \n",
    "        if unique_x:\n",
    "            seen_x.add(x)\n",
    "        \n",
    "        if x == y:\n",
    "            correct.append(x)\n",
    "            \n",
    "        if drop_correct:\n",
    "            if x != y:\n",
    "                new_X.append(x)\n",
    "                new_Y.append(y)\n",
    "        else:\n",
    "            new_X.append(x)\n",
    "            new_Y.append(y)\n",
    "    \n",
    "    \n",
    "    X = np.array(new_X)\n",
    "    Y = np.array(new_Y)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    train, val, test = prepare_dataset(X, Y, token_list, train_val_test)\n",
    "    correct = prepare_dataset(correct, correct, token_list, train_val_test=[0, 0, 1.0])[2]\n",
    "    \n",
    "    \n",
    "    return train, val, test, correct\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.7/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# When your are done playing with the toy data, try solving this problem\n",
    "train, val, test, correct = load_surnames_dataset(\"./train.csv\", drop_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batcher = DataLoader(train, collate_fn=collate_sequences, batch_size=64, shuffle=True)\n",
    "val_batcher = DataLoader(val, collate_fn=collate_sequences, batch_size=64, shuffle=False)\n",
    "test_batcher = DataLoader(test, collate_fn=collate_sequences, batch_size=256, shuffle=False)\n",
    "correct_batcher = DataLoader(correct, collate_fn=collate_sequences, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_result_test = evaluate_test(\n",
    "    seq2seq_model, test_batcher, loss_object, max_batches=100000, tag=\"test\", params=params\n",
    ")\n",
    "\n",
    "evaluate_result_train = evaluate_test(\n",
    "    seq2seq_model, train_batcher, loss_object, max_batches=100, tag=\"train\", params=params\n",
    ")\n",
    "\n",
    "evaluate_result_val = evaluate_test(\n",
    "    seq2seq_model, val_batcher, loss_object, max_batches=100, tag=\"val\", params=params\n",
    ")\n",
    "\n",
    "evaluate_result_correct = evaluate_test(\n",
    "    seq2seq_model, correct_batcher, loss_object, max_batches=100, tag=\"correct\", params=params\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_py3",
   "language": "python",
   "name": "base_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
